{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5EIvqNsg2pG"
   },
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l95kqyVHkoxB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8O2ci5G9bigC"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6kG2ZYBc2hE"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE=1000\n",
    "TEST_SIZE=1000\n",
    "VAL_SIZE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P-3GHV-Fb5cv"
   },
   "outputs": [],
   "source": [
    "# Use my dataset\n",
    "data_dir = \"/home/ubuntu/cs230/UTKFace/*_*_*_*\"\n",
    "# list_files lists files in a shuffled order\n",
    "list_ds = tf.data.Dataset.list_files(data_dir, seed=8)\n",
    "\n",
    "# Convert data_dir to a Path object and count images\n",
    "data_dir = pathlib.Path(data_dir[:-7])\n",
    "image_count = len(list(data_dir.glob('*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvED8cFlb5c4"
   },
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts_1 = tf.strings.split(file_path, \"/\")\n",
    "    parts = tf.strings.split(parts_1[-1], \"_\")\n",
    "#     if len(parts)>3:\n",
    "#         parts = '0'\n",
    "    return int(parts[0])\n",
    "    \n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qReQ1A9b5dF"
   },
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "test_batches = labeled_ds.take(TEST_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = labeled_ds.skip(TEST_SIZE).take(VAL_SIZE).batch(BATCH_SIZE)\n",
    "train_batches = labeled_ds.skip(TEST_SIZE + VAL_SIZE).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_pos (y_true, y_pred):\n",
    "#     ans = (y_pred <= 15 and y_true >= 15)\n",
    "    ans = (1-tf.math.maximum(0.0,y_pred-15)/(y_pred-15 + 0.001))*(tf.math.maximum(0.0,y_true-15)/(y_true-15+0.001))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_neg (y_true, y_pred):\n",
    "#     ans = (y_pred >= 15 and y_true <= 15)\n",
    "    ans = (tf.math.maximum(0.0,y_pred-15)/(y_pred-15 + 0.001))*(1-tf.math.maximum(0.0,y_true-15)/(y_true-15+0.001))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_neg (y_true, y_pred):\n",
    "#     ans = (y_pred >= 15 and y_true >= 15)\n",
    "    ans = (tf.math.maximum(0.0,y_pred-15)/(y_pred-15+0.001))*(tf.math.maximum(0.0,y_true-15)/(y_true-15+0.001))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_pos (y_true, y_pred):\n",
    "#     ans = (y_pred <= 15 and y_true <= 15)\n",
    "    ans = (1-tf.math.maximum(0.0,y_pred-15)/(y_pred-15+0.001))*(1-tf.math.maximum(0.0,y_true-15)/(y_true-15+0.001))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minor_accuracy (y_true, y_pred):\n",
    "    ans = true_neg(y_true,y_pred)+true_pos(y_true,y_pred)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just for a sanity check\n",
    "def combined (y_true, y_pred):\n",
    "    ans = true_pos(y_true,y_pred)+false_pos(y_true,y_pred)+false_neg(y_true,y_pred)+true_neg(y_true,y_pred)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSuMN7Zbb37O"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/home/ubuntu/cs230/saved_models/final_model', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(metrics=['accuracy', tf.metrics.RootMeanSquaredError(), false_neg, false_pos, true_neg, true_pos, minor_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HYT9jDS8b35X",
    "outputId": "2e831297-dcbe-4701-fd67-f98fb8ef5064"
   },
   "outputs": [],
   "source": [
    "loss0, accuracy0, rmse0, false_neg0, false_pos0, true_neg0, true_pos0, minor_accuracy0 = model.evaluate(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision0 = precision(true_pos0, false_pos0)\n",
    "recall0 = recall(true_pos0, false_neg0)\n",
    "fOne0 = fOne(precision0, recall0)\n",
    "\n",
    "print(\"Precision: \", precision0)\n",
    "print(\"Recall: \", recall0)\n",
    "print(\"F1 Score: \", fOne0)\n",
    "print(\"RMSE: \", rmse0)\n",
    "print(\"Minor Accuracy: \", minor_accuracy0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer VGG Face - First Pass",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
